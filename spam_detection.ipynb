{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c739dffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: nltk in ./.venv/lib/python3.11/site-packages (3.9.2)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.11/site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.11/site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas scikit-learn nltk tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b588c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c56bc4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spam</td>\n",
       "      <td>viiiiiiagraaaa\\nonly for the ones that want to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ham</td>\n",
       "      <td>got ice thought look az original message ice o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spam</td>\n",
       "      <td>yo ur wom an ne eds an escapenumber in ch ma n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spam</td>\n",
       "      <td>start increasing your odds of success &amp; live s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ham</td>\n",
       "      <td>author jra date escapenumber escapenumber esca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0  Spam  viiiiiiagraaaa\\nonly for the ones that want to...\n",
       "1   Ham  got ice thought look az original message ice o...\n",
       "2  Spam  yo ur wom an ne eds an escapenumber in ch ma n...\n",
       "3  Spam  start increasing your odds of success & live s...\n",
       "4   Ham  author jra date escapenumber escapenumber esca..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam_Emails_data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8aa15d",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc2bd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1494bff6",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceaad4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df['label']\n",
    "\n",
    "label = LabelEncoder()\n",
    "target = label.fit_transform(target)\n",
    "label_names=['Spam','Ham'] # 0 -> Ham, 1 -> Spam\n",
    "label_order=label.transform(label_names)\n",
    "\n",
    "target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a815af0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/I568645/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/I568645/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/I568645/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/I568645/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedf6393",
   "metadata": {},
   "source": [
    "#### Lowercase, Replace non-alphamumeric, Tokenize, Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9594d5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193852/193852 [01:51<00:00, 1733.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>viiiiiiagraaaa\\nonly for the ones that want to...</td>\n",
       "      <td>viiiiiiagraaaa one want make scream prodigy sc...</td>\n",
       "      <td>[viiiiiiagraaaa, one, want, make, scream, prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>got ice thought look az original message ice o...</td>\n",
       "      <td>got ice thought look original message ice oper...</td>\n",
       "      <td>[got, ice, thought, look, original, message, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yo ur wom an ne eds an escapenumber in ch ma n...</td>\n",
       "      <td>wom ed escapenumber arn ific ati ons escapelon...</td>\n",
       "      <td>[wom, ed, escapenumber, arn, ific, ati, ons, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>start increasing your odds of success &amp; live s...</td>\n",
       "      <td>start increasing odds success live sexually he...</td>\n",
       "      <td>[start, increasing, odds, success, live, sexua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>author jra date escapenumber escapenumber esca...</td>\n",
       "      <td>author jra date escapenumber escapenumber esca...</td>\n",
       "      <td>[author, jra, date, escapenumber, escapenumber...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  viiiiiiagraaaa\\nonly for the ones that want to...   \n",
       "1  got ice thought look az original message ice o...   \n",
       "2  yo ur wom an ne eds an escapenumber in ch ma n...   \n",
       "3  start increasing your odds of success & live s...   \n",
       "4  author jra date escapenumber escapenumber esca...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  viiiiiiagraaaa one want make scream prodigy sc...   \n",
       "1  got ice thought look original message ice oper...   \n",
       "2  wom ed escapenumber arn ific ati ons escapelon...   \n",
       "3  start increasing odds success live sexually he...   \n",
       "4  author jra date escapenumber escapenumber esca...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [viiiiiiagraaaa, one, want, make, scream, prod...  \n",
       "1  [got, ice, thought, look, original, message, i...  \n",
       "2  [wom, ed, escapenumber, arn, ific, ati, ons, e...  \n",
       "3  [start, increasing, odds, success, live, sexua...  \n",
       "4  [author, jra, date, escapenumber, escapenumber...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text: str):\n",
    "    \"\"\"Lowercase, remove non-alphanumeric chars, tokenize, remove stopwords, lemmatize.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    # eeplace non-alphanumeric characters with space\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    # tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # remove stopwords & very short tokens\n",
    "    tokens = [t for t in tokens if t not in stop_words and len(t) > 2]\n",
    "    # lemmatize\n",
    "    lemmas = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    return ' '.join(lemmas), lemmas\n",
    "\n",
    "\n",
    "result_series = df['text'].progress_apply(preprocess)\n",
    "df[['clean_text', 'tokens']] = result_series.apply(pd.Series)\n",
    "\n",
    "df[['text','clean_text', 'tokens']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8da2eaa",
   "metadata": {},
   "source": [
    "#### Clean potential empty rows\n",
    "stop word removal could lead to empty mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51dc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows removed: 262; Remaining: 193590\n"
     ]
    }
   ],
   "source": [
    "# remove rows where clean_text is empty or tokens is an empty list\n",
    "mask = (\n",
    "    df['clean_text'].notna() &\n",
    "    df['tokens'].notna() &\n",
    "    (df['clean_text'].str.strip() != \"\") &\n",
    "    df['tokens'].apply(lambda t: isinstance(t, list) and len(t) > 0)\n",
    ")\n",
    "removed_count = len(df) - mask.sum()\n",
    "df = df[mask].copy()\n",
    "\n",
    "# re-align target with filtered df\n",
    "target = label.transform(df['label'])\n",
    "\n",
    "print(f\"Rows removed: {removed_count}; Remaining: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cc3c9d",
   "metadata": {},
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "157fe804",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['tokens']\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d13035",
   "metadata": {},
   "source": [
    "#### Feature Extraction (TF-IDF and Ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fc80d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I568645/git/ANLP-Mailsense/.venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# dummy tokenizer (to use pre-tokenized input)\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    preprocessor=identity_tokenizer, # Skip preprocessing\n",
    "    tokenizer=identity_tokenizer      # Use the pre-tokenized list\n",
    ")\n",
    "\n",
    "# create tf-idf vectors\n",
    "X_tfidf = vectorizer.fit_transform(data_train)\n",
    "X_test_tfidf = vectorizer.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92f8242",
   "metadata": {},
   "source": [
    "#### Train and Test with MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca11a8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     20362\n",
      "           1       0.99      0.94      0.96     18356\n",
      "\n",
      "    accuracy                           0.97     38718\n",
      "   macro avg       0.97      0.97      0.97     38718\n",
      "weighted avg       0.97      0.97      0.97     38718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_model = MultinomialNB()\n",
    "\n",
    "# train\n",
    "mnb_model.fit(X_tfidf, target_train)\n",
    "\n",
    "# predict\n",
    "y_pred = mnb_model.predict(X_test_tfidf)\n",
    "\n",
    "# evaluate\n",
    "print(\"--- Test Set Performance ---\")\n",
    "print(classification_report(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8df8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Set Performance ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     81775\n",
      "           1       1.00      0.97      0.98     73097\n",
      "\n",
      "    accuracy                           0.98    154872\n",
      "   macro avg       0.98      0.98      0.98    154872\n",
      "weighted avg       0.98      0.98      0.98    154872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# overfitting check\n",
    "y_train_pred = mnb_model.predict(X_tfidf)\n",
    "\n",
    "print(\"--- Training Set Performance ---\")\n",
    "print(classification_report(target_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2183ed8c",
   "metadata": {},
   "source": [
    "-> should not be overfittet, model performance just slightly(1%) better on train data than on test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
